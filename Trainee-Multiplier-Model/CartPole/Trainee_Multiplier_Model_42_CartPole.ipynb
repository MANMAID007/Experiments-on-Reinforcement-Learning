{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52b8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random, copy\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719747ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "BUFFER_CAPACITY = 1000000\n",
    "T_LR = 0.001\n",
    "BUFFER_FILL_MATCH_COUNT = 256\n",
    "BEST_MATCHES_COUNT = 8\n",
    "VARIATION_RANGE = 2\n",
    "GAMMA = 0.995\n",
    "BATCH_SIZE = 128\n",
    "RACE_COUNT = 10\n",
    "NUM_MODEL = 10\n",
    "NUM_EPOCH = 10\n",
    "FINAL_RACE_COUNT = 5\n",
    "RACE_PERCENT = 20\n",
    "BEST_N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f096728",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = \"plots/Trainee_Multiplier_Model_42_CartPole/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2131d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48286c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def random_mul(val):\n",
    "    '''\n",
    "    gerates random number around 1\n",
    "    val: deviation from 1\n",
    "    '''\n",
    "    return random.uniform(1 - val, 1 + val)\n",
    "\n",
    "def max_two_index(l):\n",
    "    m = sorted(l)\n",
    "    n = m[-1]\n",
    "    max_index_1 = [x for x in range(len(l)) if l[x] == n]\n",
    "    o = [x for x in m if x != n]\n",
    "    if len(o) == 0:\n",
    "        return sorted(max_index_1)\n",
    "    else:\n",
    "        p = o[-1]\n",
    "        max_index_2 = [x for x in range(len(l)) if l[x] == p]\n",
    "        return sorted(max_index_1 + max_index_2)\n",
    "\n",
    "def max_val_index(l):\n",
    "    m = sorted(l)\n",
    "    n = m[-1]\n",
    "    max_index = [x for x in range(len(l)) if l[x] == n]\n",
    "    return n, max_index[0]\n",
    "\n",
    "def max_indices(l, length):\n",
    "    m = list(set(l))\n",
    "    n = sorted(m, reverse=True)\n",
    "    o = min(length, len(n))\n",
    "    p = n[:o]\n",
    "    q = []\n",
    "    for i in range(len(l)):\n",
    "        for el in p:\n",
    "            if el == l[i]:\n",
    "                q.append(i)\n",
    "    return sorted(list(set(q)))\n",
    "\n",
    "def good_val_indices(l, percent, rank):\n",
    "    m = max(l)\n",
    "    n = min(l)\n",
    "    o = m - (m - n) * (percent / 100)\n",
    "    p1 = [i for i in range(len(l)) if l[i] == m]\n",
    "    if len(p1) >= rank:\n",
    "        return sorted(p1[:rank])\n",
    "    q1 = [el for el in l if el != m]\n",
    "    m1 = max(q1)\n",
    "    p2 = [i for i in range(len(l)) if l[i] == m1][0]\n",
    "    p = [i for i in range(len(l)) if o <= l[i] <= m]\n",
    "    q = list(set(p).intersection(set([p2, p1[0]])))\n",
    "    return sorted(q)\n",
    "\n",
    "def biased_mean(l):\n",
    "    if len(l) < 100:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(l) / len(l)\n",
    "\n",
    "def quad(x, r):\n",
    "    return - 10 * ((x*x/(r+1))-x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f879fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainee:\n",
    "    def __init__(self, state_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.model = self.nn_model()\n",
    "        self.opt = tf.keras.optimizers.Adam(T_LR)\n",
    "\n",
    "    def nn_model(self):\n",
    "        inputs = Input((self.state_dim,))\n",
    "        d1 = Dense(32, activation=\"relu\")(inputs)\n",
    "        d2 = Dense(32, activation=\"relu\")(d1)\n",
    "        outputs = Dense(1, activation=\"sigmoid\")(d2)\n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = np.array(state)\n",
    "        predicted = self.model.predict(state)\n",
    "        return 1 if predicted > 0.5 else 0\n",
    "\n",
    "    def train(self, states, r_grads):\n",
    "        r_grads = tf.convert_to_tensor(r_grads, dtype=tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            x = self.model(states, training=True)\n",
    "            grads = tape.gradient(x, self.model.trainable_variables, r_grads)\n",
    "        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58080a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def store(self, info):\n",
    "        self.buffer.append(info)\n",
    "\n",
    "    def sample(self):\n",
    "        sample = random.sample(self.buffer, BATCH_SIZE)\n",
    "        states, r_grads = map(np.asarray, zip(*sample))\n",
    "        states = np.array(states).reshape(BATCH_SIZE, -1)\n",
    "        r_grads = np.array(r_grads).reshape(BATCH_SIZE, -1)\n",
    "        return states, r_grads\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00da5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env_name):\n",
    "        self.env = gym.make(env_name)\n",
    "        self.state_dim = self.env.observation_space.shape[0]\n",
    "        self.action_dim = self.env.action_space.n\n",
    "        self.trs = [Trainee(self.state_dim) for _ in range(NUM_MODEL)]\n",
    "        self.buffer = ReplayBuffer(BUFFER_CAPACITY)\n",
    "        self.best_model = self.trs[0]\n",
    "\n",
    "    def runners(self, model_list, weights, indices):\n",
    "        delisted_indices = [i for i in range(NUM_MODEL) if i not in indices]\n",
    "        for i in delisted_indices:\n",
    "            updated_weights = [x * random_mul(VARIATION_RANGE) for x in weights]\n",
    "            model_list[i].model.set_weights(updated_weights)\n",
    "        return model_list\n",
    "\n",
    "    def buffer_filler(self, best_model, index):\n",
    "        temp_buffer_list = []\n",
    "        ep_return_list = []\n",
    "        for _ in range(BUFFER_FILL_MATCH_COUNT):\n",
    "            ep_return = 0\n",
    "            temp_buffer = []\n",
    "            return_t = 0\n",
    "            done = False\n",
    "            state = self.env.reset()\n",
    "            while not done:\n",
    "                action = best_model.get_action([state])\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                state = next_state\n",
    "                ep_return += reward\n",
    "                # r_grad = - (reward + (1 - GAMMA) * return_t) / (return_t + 0.1)\n",
    "                x = reward + (1 - GAMMA) * return_t\n",
    "                r_grad = quad(x, return_t)\n",
    "                return_t = reward + GAMMA * return_t\n",
    "                temp_buffer.append([state, r_grad])\n",
    "            ep_return_list.append(ep_return)\n",
    "            temp_buffer_list.append(temp_buffer)\n",
    "        imp_index = max_indices(ep_return_list, BEST_MATCHES_COUNT)\n",
    "        num_stored = 0\n",
    "        for i in imp_index:\n",
    "            for x in temp_buffer_list[i]:\n",
    "                num_stored += 1\n",
    "                self.buffer.store(x)\n",
    "        for_plot = [ep_return_list[i] for i in imp_index]\n",
    "        plt.plot(for_plot)\n",
    "        plt.title(f\"Buffer input Returns of race {index} with injection {num_stored}\")\n",
    "        plt.savefig(plot_path + f\"buffer_returns_{index}.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    def train_from_buffer(self, model_list):\n",
    "        for m in model_list:\n",
    "            for _ in range(NUM_EPOCH):\n",
    "                states, r_grads = self.buffer.sample()\n",
    "                m.train(states, r_grads)\n",
    "    \n",
    "    def race(self, model_list, index):\n",
    "        race_avg = [0] * NUM_MODEL\n",
    "        for i in range(NUM_MODEL):\n",
    "            reward_sum = 0\n",
    "            for _ in range(RACE_COUNT):\n",
    "                done = False\n",
    "                state = self.env.reset()\n",
    "                while not done:\n",
    "                    action = model_list[i].get_action([state])\n",
    "                    next_state, reward, done, _ = self.env.step(action)\n",
    "                    state = next_state\n",
    "                    reward_sum += reward\n",
    "            race_avg[i] = reward_sum / RACE_COUNT\n",
    "        plt.plot(race_avg)\n",
    "        plt.title(f\"Racer Returns of race {index}\")\n",
    "        plt.savefig(plot_path + f\"race_avg_returns_{index}.png\")\n",
    "        plt.show()\n",
    "        return race_avg\n",
    "\n",
    "    def train(self):\n",
    "        i = 0\n",
    "        for_plot = []\n",
    "        ma = []\n",
    "        model_list = self.trs\n",
    "        while i < FINAL_RACE_COUNT and biased_mean(ma) < 200:\n",
    "            print(f\"Starting filling buffer: {i}...\")\n",
    "            self.buffer_filler(self.best_model, i)\n",
    "            print(\"Training starts...\")\n",
    "            self.train_from_buffer(model_list)\n",
    "            print(f\"Buufer size: {self.buffer.size()}, Starting race {i}\")\n",
    "            race_avg = self.race(model_list, i)\n",
    "            print(\"Race complete!\")\n",
    "            max_ep_reward, best_model_index = max_val_index(race_avg)\n",
    "            good_model_indices = good_val_indices(race_avg, RACE_PERCENT, BEST_N)\n",
    "            self.best_model = self.trs[best_model_index]\n",
    "            for_plot.append(max_ep_reward)\n",
    "            ma = for_plot[-(len(for_plot) if len(for_plot) < 100 else 100):]\n",
    "            print(f\"At race {i}, finalist model is Model#({best_model_index}) with episode reward {max_ep_reward}\")\n",
    "            print(f\"carrying following Model numbers: {good_model_indices}\")\n",
    "            new_weights = model_list[best_model_index].model.get_weights()\n",
    "            model_list = self.runners(model_list, new_weights, good_model_indices)\n",
    "            i += 1\n",
    "        plt.plot(for_plot)\n",
    "        plt.title(\"Final Return Plot\")\n",
    "        plt.savefig(plot_path + \"Final_Returns.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    def get_final_weights(self):\n",
    "        return self.best_model.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46ca5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts at 21-12-10, 09:16:25\n",
      "Starting filling buffer: 0...\n"
     ]
    }
   ],
   "source": [
    "a = Agent(\"CartPole-v1\")\n",
    "print(f\"Starts at {datetime.now().strftime('%y-%m-%d, %H:%M:%S')}\")\n",
    "a.train()\n",
    "print(f\"Ends at {datetime.now().strftime('%y-%m-%d, %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e3e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
